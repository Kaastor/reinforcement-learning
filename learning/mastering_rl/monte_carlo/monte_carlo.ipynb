{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### The need for a complete model of the environment\n",
    "\n",
    "In the methods we have used so far, we have relied on the transition probabilities of the\n",
    "environment in our policy evaluation, policy iteration, and value iteration algorithms to\n",
    "obtain optimal policies. This is a luxury that we usually don't have in practice. It is either\n",
    "these probabilities are very difficult to calculate for each possible transition (which is often\n",
    "impossible to even enumerate), or we simply don't know them. You know what is much\n",
    "easier to obtain? A sample trajectory of transitions, either from the environment itself\n",
    "or from its simulation. In fact, simulation is a particularly important component in RL,\n",
    "as we will discuss separately towards the end of this chapter.\n",
    "Then the question becomes how we use sample trajectories to learn near-optimal policies.\n",
    "Well, this is exactly what we'll cover next in the rest of this chapter with Monte Carlo and\n",
    "TD methods. The concepts you will learn are at the center of many of the advanced RL\n",
    "algorithms.\n",
    "\n",
    "## Monte Carlo\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}